#### Tensors

类似于`numpy`的`ndarrays`;

```python
import torch

x = torch.tensor([4, 1.])  # 根据list得到对应的tensor
print(x)
print(torch.ones_like(x).numpy()) # 生成相同维数、全为1的tensor,并且转为numpy

#output: 
	tensor([4., 1.])
    

    
    
    
import torch

x = torch.tensor([[4, 1.]])
y = torch.rand_like(x)
print(x)
print(y)

result = torch.empty(x.size())  # 结果tensor
torch.add(x, y, out=result) 

print(result)

#output:
tensor([[4., 1.]])
tensor([[0.5500, 0.8570]])
tensor([[4.5500, 1.8570]])
```

#### Autograd

自动梯度计算

`tensor`含有的 `.requires_grad`属性，能够决定是否在运算`tensor`过程中记录过程

运算过程中，`tensor`将会有 `grad_fn`属性，用于记录生成该`tensor`的函数

```python
import torch

x = torch.ones(size=(4, 3), requires_grad=True)
# print(x)

y = x + 2
# print(y)
z = y * y * 3
out = z.mean()

print(z, out)

# output:
tensor([[27., 27., 27.],
        [27., 27., 27.],
        [27., 27., 27.],
        [27., 27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)
```

##### Gradient

