##### 假设空间

所有features的集合 + ∅

##### 版本空间 version space

由假设空间得出的进一步的空间

使得拥有的经验具有一定的泛化能力

##### 归纳偏好  inductive bias

------



##### NFL No Free Lunch

得到的分类模型和算法本身无关

但这是在**所有问题出现可能相同的基础上**

#### 推导

###### 训练结果误差与学习方法无关

$$
P(h\mid X,\sigma_a)
$$
为

$$
\sigma_a算法
$$

下，X为数据时的h函数概率

$$
E_{ote}（\sigma_a\mid X,f）=\sum_{h}\sum_{x\in X-x}P(x)\coprod(h(x)\ne f)P(h\mid X,\sigma_a)
$$

------

其中
$$
\coprod(h(x)\ne f)
$$
为指示函数：当内容为真即1，假为0

因为任何目标函数都可以映射到 {0,1}， 函数空间为
$$
{\{0,1\}}^{\mid x\mid}
$$
即函数的个数,并且假设 f 呈现<u>均匀分布</u>
$$
\sum_fE_{ote}（\sigma_a\mid X,f）=
\sum_f\sum_{h}\sum_{x\in X-x}P(x)\coprod(h(x)\ne f)P(h\mid X,\sigma_a)
\\=
\sum_f\coprod(h(x)\ne f)\sum_hP(h\mid X,\sigma_a)\sum_{x\in X-x}P(x)
\\=
\sum_hP(h\mid X,\sigma_a)\sum_{x\in X-x}P(x)\frac122^{\mid x\mid}
\\
=\sum_{x\in X-x}P(x)\frac122^{\mid x-1\mid}
$$
