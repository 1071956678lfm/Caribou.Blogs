## 线性模型

### 线性回归

#### 表示形式

###### 在回归任务的情形下，我们需要通过调整线性函数的参数，来尽可能缩小[均方误差]，即欧氏距离

$$
f(\vec x_i)=\vec{w}^T\vec{x_i}+\vec b , 使得f(x_i)\approx y_i
$$

​	称为多元线性回归

为了缩小均方误差，若为一元线性回归
$$
(w^*,b^*)=argmin_{(w,b)}\sum_{i=1}^m(f(x_i)-y_i)^2\\
=argmin_{(w,b)}\sum_{i=1}^m(y_i-wx_i-b_i)^2
$$
通过均方误差求解的过程，称为**最小二乘**

接下来对于多元线性回归：
$$
取如下矩阵\\X=\begin{pmatrix} x_{11} & x_{12} & ... & x_{1d} & 1\\ 
x_{21} & x_{22} & ... & x_{2d} & 1\\ 
. & . & ... & . & .\\ 
. & . & ... & . & .\\ 
x_{m1} & x_{m2} & ... & x_{md} & 1\\ 
\end{pmatrix} 
=\begin{pmatrix}
X_1^T & 1\\
X_2^T & 1\\
. & . \\
. & . \\
X_m^T & 1

\end{pmatrix}\\
令\hat{w}=\begin{bmatrix}w\\b\end{bmatrix},
\hat{x_i}=\begin{bmatrix}x_i\\1\end{bmatrix}
\\那么\,x_i^Tw+b=\hat{x_i}^T\hat{w}
$$

##### 梯度

- 方向导数为各个方向上的导数
- 梯度的方向是方向导数的最大值方向，梯度的值是方向导数的最大值

$$
设f(x,y)为一个二元函数，u=cos\theta_i+sin\theta_j为一个单位向量\\
那么\lim_{t->0}\frac{}{}
$$



##### 矩阵求导

###### 矩阵内积

$$
<X,Y>=X^TY=Tr(X^TY)=\sum_{i=1}^m\sum_{j=1}^nX_{ij}Y_{ij}
$$

