#### 经验误差与过拟合

##### 错误率&误差

- 训练（经验）误差：训练集
- 测试误差：测试集
- 泛化误差：除了训练集的样本

##### 过拟合

- 添加正则项
- early stop

##### 欠拟合

- 决策树：拓展分支
- 神经网络：增加训练次数

#### 评估方法

##### 留出法

- 数据划分为互斥集合
- 数据/测试集划分尽可能保持各个分组的数据分布统一性
- 若干次随机划分，重复试验取平均（排除随机性）
- 划分比例 2:1 -> 4:1

##### 交叉验证法 k-则交叉验证

- 数据集划分为k则互斥、大小相同子集

- 取一份为测试，其他k-1份为训练集(留一法)

- 依次每一份作为测试，取平均

- K一般为10

  常用“**十次十则交叉验证**”

- 模型计算消耗比较大

##### 自助法/自举法

- D含有m个数据，放回采样取m次得到D‘ ， **D/D'**作为测试集

- 样本一次也没选中概率：
  $$
  \lim_{m->\inf} (1-\frac{1}{m})^m -> \frac{1}{e}\approx0.368
  $$
  

#### 性能度量

##### 均方误差

对于数据分布D，要评估f 学习器的性能
$$
E(f;D) =\frac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2
$$

一般的，对于概率密度 p(*)
$$
E(f;D)={\int_{x-D}}(f(x)-y)^{2}p(x)dx
$$

##### 错误率&精度

错误率
$$
E(f;D)=\frac1m\sum_{i=1}^m\coprod(f(x_i)\ne{y_i})
$$
精度
$$
acc(f;D)=\frac1m\sum_{i=1}^m\coprod(f(x_i=y_i))\\
=1-E(f;D)
$$


##### 查准率&查全率

condition positive(P) : 测试数据中正例

true positive(TP) : 是正例，并且预测也是正例

false negative(FN) : 是正例，但预测反例

true negative(TN): 反例，预测的也是反例

false positive(FP) : 反例，但预测正例



真正例(true positive) 真反例(true negative) 假正例(false positive) 假反例(false negative)

则
$$
N_{总}=TP+TN+FP+FN\\
\begin{array}{c|cc}
&\text{正例}&\text{反例}\\
\hline
\text{真例}& TP&FN\\
\hline
\text{假例}&FP&TN
\end{array}
$$

###### P查准率: 正例被检验正确 在  全部真实情况中的比例（预测为正例中的确为正例的比例

$$
P=\frac{TP}{TP+FP}
$$

###### R查全率：真实情况为正例子，预测为正的比例（正例中预测成功的比例

也称为 **召回率/灵敏度**
$$
R=\frac{TP}{TP+FN} = \frac{TP}{P}
$$



###### PR曲线：查准率y轴，查全率x轴

​	平衡点 (Break-Even Point) BEP, 此处P=R

##### F1度量

$$
F1=\frac{2\times P\times R}{P+R}
=\frac{2\times TP}{\text{样例总数}+TP-TN}
$$

​	基于调和平均来定义
$$
\frac1{F1}=\frac12\times{(\frac1P+\frac1R)}
$$

##### Fβ  加入度量的权值

​	是F1度量的一般形式
$$
F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}
$$
​	当β > 1 ，对R查全率有偏重；当β < 1 , 对P查准率有偏重

------

以上均为简单二分；当有多个二分时，需要产生n个混淆矩阵

1. 两两求出 Pi , Ri
2. 计算平均

##### macro-P 宏查准率

$$
macro-P=\frac1n\sum_{i=1}^mP_i
$$

##### macro-R 宏查全率

$$
macro-R=\frac1n\sum_{i=1}^mR_i
$$

##### macro-F1 宏F1

$$
macro-F1=\frac{2\times macroP\times macroR}{macroP+macroR}
$$

------

此外，还可以先求TP, TN , FP , FN均值，再进行PR求解

##### micro-P 微查准率

$$
micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}
$$

##### micro-R 微查全率

$$
micro-R=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}
$$



##### ROC曲线：

1. 容易得出任意界限时的对类别的识别能力
2. 选择最佳的诊断界限值。ROC曲线越靠近左上角,试验的准确性就越高。最靠近左上角的ROC曲线的点是错误最少的最好阈值，其假阳性和假阴性的总数最少。

###### 纵轴：真正例率(TPR) / 灵敏度 / 召回率

$$
TPR = \frac{TP}{TP+FN}=\frac{TP}{P}
$$

###### 横轴：假正例率(FPR) / 误诊率 /  (1 -  特异度)

预测为正但是实际为负的  占**所有负例**的比例
$$
FPR=\frac{FP}{FP+TN}=\frac{FP}{N}
$$
ROC曲线是以FPR为横坐标，以TPR为纵坐标，以<u>概率为阈值</u>来度量模型<u>正确识别正实例的比例</u>, 与模型<u>错误的把负实例识别成正实例的比例</u>之间的权衡，TPR的增加必定以FPR的增加为代价，ROC曲线下方的面积是模型准确率的度量

##### AUC

###### The AUC value is equivalent to the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.

- ROC曲线绘制推导

  将正反例全部排序。设一开始的阈值为最大，也就是所有均为反例，取点 (0,0)

  若下一个点为<u>正例</u>
  $$
  1.TP=TP+1\\
  2.TPR=\frac{TP+1}{TP+1+FN-1}\\=\frac{TP+1}{m^+}\\=\frac{TP}{m^+}+\frac1{m^+}\\
  =TPR+\frac{1}{m^+}
  \\得 y=y+\frac{1}{m^+}
  $$
  此外，如果有多个分类器得分一致，取其**对角线**来进行绘制即可（数学期望值）

- ROC曲线下方面积

$$
AUC=\frac12\sum_{i=1}^{m-1}{(x_{i+1}-x_i)}{(y_i+y_{i+1})}
$$

​	也即<u>梯形累加</u>

- 由于ROC曲线和数据的正例、反例排序有关. 存在排序误差

$$
o_{rank}=\frac1{m^+\times m^-}\sum_{x^+\in D^+}\sum_{x^-\in D^-}{(\coprod((f(x^+)<f(x^-))+\frac12\coprod(f(x^+)=f(x^-)))}
$$

###### 若正例预测小于反例，记一个罚分；若等于，记0.5个罚分

​	理解：

根据绘制ROC曲线的内容，一个正例，图像向上一步；一个反例，图像向右一步

那么对于所有的正例，其**横坐标**就是**得分比它高**的反例个数

###### 评价：

​	ROC曲线和和测试样本的**分布**、样本的**误分类代价**无关



##### 代价敏感错误率&代价曲线

代价矩阵：cost(ij)表示将第i类预测为第j类的代价
$$
\begin{array}{c|cc}
&\text{第0类}&\text{第1类}\\
\hline
\text{第0类}& &cost_{01}\\
\hline
\text{第1类}&cost_{10}&
\end{array}
$$
之前我们考虑的都是**均等代价**

- 错误率

$$
E(f;D)=\frac1m\sum_{i=1}^m\coprod(f(x_i)\ne{y_i})
$$

现在需要考虑**不均等代价**

- 代价敏感错误率

  加权即可
  $$
  E(f;D;cost)=\frac1m(\sum_{x_i\in{D^+}}\coprod{f(x_i\neq{y_i})cost_{01}+\sum_{x_i\in{D^-}}\coprod{(f(x_i\ne{y_i})cost_{10})}})
  $$

##### 代价曲线

###### 横轴

- 正例概率代价

$$
P(+)cost=\frac{p\times{cost_{01}}}{p\times{cost_{01}}+(1-p)\times{cost_{10}}}
$$

p为用例中正例的概率

###### 横轴

- 归一化代价

$$
cost_{norm}=\frac{FNR\times{p}\times cost_{01}+FPR\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}
$$

其中FNR为假反例率 ； FPR为假正例率

即：
$$
FNR=\frac{FN}{P}\\
FPR=\frac{FP}{N}
$$

- 二分类问题中，一个分类器有一个**阈值**。阈值对应ROC曲线的一个点，对应代价曲线的一条线段

------

以下是知乎回答“代价曲线”的理解，我个人整理一下：[url][https://www.zhihu.com/question/63492375/answer/247885093]

设二分的分类器
$$
\eta为阈值\\
if (x>\eta)->decide H_1
\\else ->decide H_0
$$
那么期望代价
$$
E[Cost]=\sum_{i=0}^1\sum_{j=0}^1c_{ij}Pr[decideH_i|H_j]\times{Pr[H_j]}
$$
条件概率即：
$$
Pr[decideH_1|H_0]=FPR\\
Pr[decideH_1|H_1]=TPR\\
Pr[decideH_0|H_1]=FNR\\
Pr[decideH_0|H_0]=TNR
$$
Pr [Hj]为先验概率. 而C00, C11都是0
$$
以p为先验概率 Pr[H_1]=\frac{m^+}{m^++m^-},则Pr[H_0]=1-p
\\E[Cost]=c_{10}\times(1-p)\times FPR+c_{01}\times p\times FNR
$$
