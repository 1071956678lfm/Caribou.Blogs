#### 经验误差与过拟合

##### 错误率&误差

- 训练（经验）误差：训练集
- 测试误差：测试集
- 泛化误差：除了训练集的样本

##### 过拟合

- 添加正则项
- early stop

##### 欠拟合

- 决策树：拓展分支
- 神经网络：增加训练次数

#### 评估方法

##### 留出法

- 数据划分为互斥集合
- 数据/测试集划分尽可能保持各个分组的数据分布统一性
- 若干次随机划分，重复试验取平均（排除随机性）
- 划分比例 2:1 -> 4:1

##### 交叉验证法 k-则交叉验证

- 数据集划分为k则互斥、大小相同子集

- 取一份为测试，其他k-1份为训练集(留一法)

- 依次每一份作为测试，取平均

- K一般为10

  常用“**十次十则交叉验证**”

- 模型计算消耗比较大

##### 自助法/自举法

- D含有m个数据，放回采样取m次得到D‘ ， **D/D'**作为测试集

- 样本一次也没选中概率：
  $$
  \lim_{m->\inf} (1-\frac{1}{m})^m -> \frac{1}{e}\approx0.368
  $$
  

#### 性能度量

##### 均方误差

对于数据分布D，要评估f 学习器的性能
$$
E(f;D) =\frac{1}{m}\sum_{i=1}^m (f(x_i)-y_i)^2
$$

一般的，对于概率密度 p(*)
$$
E(f;D)={\int_{x-D}}(f(x)-y)^{2}p(x)dx
$$

##### 错误率&精度

错误率
$$
E(f;D)=\frac1m\sum_{i=1}^m\coprod(f(x_i)\ne{y_i})
$$
精度
$$
acc(f;D)=\frac1m\sum_{i=1}^m\coprod(f(x_i=y_i))\\
=1-E(f;D)
$$


##### 查准率&查全率

condition positive(P) : 测试数据中正例

true positive(TP) : 是正例，并且预测也是正例

false negative(FN) : 是正例，但预测反例

true negative(TN): 反例，预测的也是反例

false positive(FP) : 反例，但预测正例



真正例(true positive) 真反例(true negative) 假正例(false positive) 假反例(false negative)

则
$$
N_{总}=TP+TN+FP+FN\\
\begin{array}{c|cc}
&\text{正例}&\text{反例}\\
\hline
\text{真例}& TP&FN\\
\hline
\text{假例}&FP&TN
\end{array}
$$

###### P查准率: 正例被检验正确 在  全部真实情况中的比例（预测为正例中的确为正例的比例

$$
P=\frac{TP}{TP+FP}
$$

###### R查全率：真实情况为正例子，预测为正的比例（正例中预测成功的比例

$$
R=\frac{TP}{TP+FN}
$$



###### PR曲线：查准率y轴，查重率x轴

​	平衡点 (Break-Even Point) BEP, 此处P=R

###### F1度量

$$
F1=\frac{2\times P\times R}{P+R}
=\frac{2\times TP}{\text{样例总数}+TP-TN}
$$

​	基于调和平均来定义
$$
\frac1{F1}=\frac12\times{(\frac1P+\frac1R)}
$$

###### Fβ  加入度量的权值

​	是F1度量的一般形式
$$
F_\beta=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}
$$
​	当β > 1 ，对R查全率有偏重；当β < 1 , 对P查准率有偏重

------

以上均为简单二分；当有多个二分时，需要产生n个混淆矩阵

1. 两两求出 Pi , Ri
2. 计算平均

###### macro-P 宏查准率

$$
macro-P=\frac1n\sum_{i=1}^mP_i
$$

###### macro-R 宏查全率

$$
macro-R=\frac1n\sum_{i=1}^mR_i
$$

###### macro-F1 宏F1

$$
macro-F1=\frac{2\times macroP\times macroR}{macroP+macroR}
$$

------

此外，还可以先求TP, TN , FP , FN均值，再进行PR求解

###### micro-P 微查准率

$$
micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}
$$

###### micro-R 微查全率

$$
micro-R=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}
$$



###### ROC曲线：

目的是把正样本放在负样本前面

##### 代价敏感错误率&代价曲线