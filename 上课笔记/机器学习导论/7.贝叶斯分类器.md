## 贝叶斯分类器

### 贝叶斯决策论

##### 条件风险

假设类别有$N$种，即${c_1,c_2,...,c_N}$, $\lambda_{ij}$ 是把一个标记为 $c_j$ 的样本误分类为 $c_i$ 的损失

那么样本在$x$上的条件风险如下
$$
R(c_i|x)=\sum_{j=1}^N\lambda_{ij}P(c_j|x)
$$

###### 最优化目标

寻找判定$h:X->Y$,来最小化总体风险 $R(h)=E_x[R(h(x)|x)]$

###### 贝叶斯判定准则

```
最小化条件风险，那么也能够将总体风险最小化
```

所以，我们可以在每个样本上选择能够最小化条件风险 $R(c|x)$ 的类别标记
$$
h^*(x)=\arg\min_{c\in Y}R(c|x)
$$
此时：

- $h^*(x)$称为贝叶斯分类器
- 此时的总体风险$R(h^*)$称为贝叶斯风险
- $1-R(h^*)$反映了分类器达到的最好性能

##### 判别式模型和生成式模型

| 类型       | 性质                                                    | 举例                       |
| ---------- | ------------------------------------------------------- | -------------------------- |
| 生成式模型 | 先对联合概率分布$P(x,c)$ 建模<br/>然后由此得到$P(c|x )$ | BP神经网络<br/>决策树, SVM |
| 判别式模型 | 直接建模条件概率                                        | 贝叶斯分类                 |

###### 名词

$$
P(c|x)=\frac{P(c)P(x|c)}{P(x)}
$$

- $P(c|x)$ 为最终估计量
- $P(x|c)$ 为样本$x$关于类标记$c$的**类条件概率**，或称作 **似然**
- $p(x)$ 称为 **证据**

### 极大似然估计

#### 目标

```
P(x|c)被θ唯一确定，那么我们需要利用训练集D来估计参数θ
```

为了明确起见，我们把 $P(x|c)$ 记作 $P(x|\theta_c)$ 

假设样本 **独立同分布**，那么参数$\theta_c$ 对于数据集 $D_c$ 的似然为
$$
P(D_c|\theta_c)=\prod_{x\in D_c}P(x|\theta_c)
$$
我们还定义了对数似然 $LL(\theta_c)$
$$
LL(\theta_c)=\log{P(D_c|\theta_c)}\\
=\sum_{x\in D_c}P(x|\theta_c)
$$
我们的**最优化目标**为
$$
\hat{\theta_c}=\arg\min_{\theta_c}LL(\theta_c)
$$

### 朴素贝叶斯分类器

#### 条件概率运算困难性

```
类条件概率是所有属性上的联合概率，难以从有限的训练样本中估计得到
```

#### 属性条件独立性假设

```
对已知类别，假设所有属性相互独立
```

得到
$$
P(c|x)=\frac{P(c)}{P(x)}\prod_{i=1}^d{P(x_i|c)}
$$
其中 $d$ 为属性个数 ， $x_i$ 为 第 $i$ 个属性上的取值

- 由上得到朴素贝叶斯表达式

$$
h_{nb}(x)=\arg\max_{c\in Y}P(c)\prod_{i=1}^d{P(x_i|c)}
$$

$P(c)=\frac{|D_c|}{|D|}$ , 即第 $c$ 类样本的比例；

- 对于离散属性

  $P(x_i|c)=\frac{D_{c,x_i}}{D_c}$ , 即 $D_c$ 中  在第 $i$ 个属性上取值为 $x_i$ 的样本的比例

- 对于连续属性

  假定 $p(x_i|c) \sim N(\mu,\sigma^2)$ , 则$p(x_i|c) = \frac{1}{\sqrt{2\pi}\sigma}{\exp(-\frac{(x_i-\mu)^2}{2\sigma^2})}$

##### 拉普拉斯修正

若某一个属性值 $c_i$ 未出现在样本中，需要进行**拉普拉斯修正**

假设 $N$ 是训练集 $D$ 中可能的样本数； $N_i$ 表示第 $i$ 个属性可能的取值数目
$$
P(c)=\frac{|D_c|+1}{|D|+N}\\
P(x_i|c)=\frac{|D_{x_i,c}|+1}{|D_c|+N_i}
$$

```
拉普拉斯修正实质上假设了 属性值和类别均匀分布
```

### 半朴素贝叶斯分类器

```
属性条件独立性假设在现实中很难成立——所以对该属性做一定程度的放松
```

#### 独依赖估计

```
ODE (One-Dependent Estimator)
假设每个属性在类别之外最多仅依赖其他一个属性
```

令 $pa_i$ 为属性 $x_i$ 所依赖的属性，称为 $x_i$ 的**父属性**
$$
P(x|c)=P(c)\prod_{i=1}^d{P(x_i|c,pa_i)}
$$
问题的关键在于：`如何确定每个属性的父属性`

#### 属性依赖关系

![img](https://img-blog.csdn.net/20160512153051334)

##### Super - Parent ODE

```
所有的属性依赖于同一个属性，称为‘超父’
```

##### TAN方法

```
每个属性依赖的另外的属性由最大带权生成树来确定
```

（1）先求每个属性之间的互信息来作为他们之间的**权值**。
$$
I(x_i,x_i|y)=\sum_{x_i,x_i;c\in Y }\log{\frac{P(x_i,x_j|c)}{P(x_i|c)P(x_j|c)}}
$$
（2）构建完全图。权重是刚才求得的互信息。然后用最大带权生成树算法求得此图的最大带权的生成树。

（3）找一个根变量，然后依次将图变为有向图。

##### AODE方法

```
尝试将每个属性作为超父来构建SPODE,然后将那些具有足够训练数据支撑的SPODE集成起来作为最终结果
```

$$
P(c|x)=\sum_{i=1\\|D_{x_i}|\ge m'}^dP(c,x_i)\prod_{j=1}^dP(x_j|c,x_i)
$$

- 其中 , $D_{x_i}$是在第 $i$ 个属性上取值为 $x_i$ 的样本集合
- $m'$ 为阈值常数

类似的，我们进行拉普拉斯修正
$$
{\hat{P}(c,x_i)=\frac{|D_{c,x_i}|+1}{|D|+N\times N_i}}\\
\hat{P}(x_j|c,x_i)=\frac{|D_{c,x_i,x_j}|+1}{|D_{c,x_i}|+N_j}
$$

### 贝叶斯网

```
也称为'信念网'；借助有向无环图来刻画属性之间的依赖关系，使用条件概率表来描述属性的联合概率分布
```

#### 结构

一个贝叶斯网 $B$ 由结构 $G$ 和参数 $\theta$ 两部分构成，$B = <G,\theta>$，其中每一个节点表示属性，节点之间的连线表示属性依赖关系；而 $\theta $ 表示依赖关系的量化

假设属性 $x_i$ 在 $G$ 上的父节点集为 $\pi_i$ , 那么$\theta $ 包含了每个属性的条件概率表示 $\theta_{x_i|\pi_i}=P_B(x_i|\pi_i)$

那么属性 $x_1,x_2,...,x_d$的联合概率分布
$$
P_B(x_1,x_2,...,x_d)=\prod_{i=1}^d{P_B(x_i|\pi_i)}=\prod_{i=1}^d{\theta_{x_i|\pi_i}}
$$
![img](https://img-blog.csdn.net/20141110234449486)

如上图，他们的联合概率分布为

$P_B(x_1,x_2,...,x_7)=P(x_1)P(x_2)P(x_3)P(x_4|x_1,x_2)P(x_5|x_1,x_3)P(x_6|x_4)P(x_7|x_4,x_5)$

#### 三个变量之间的典型依赖关系

##### 同父结构

![img](https://upload-images.jianshu.io/upload_images/2349903-a53df698d760f5c2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/218/format/webp)

```
c已知，那么a , b 独立
```

##### 顺序结构

![img](https://upload-images.jianshu.io/upload_images/2349903-89fd7137d3f1eda0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/358/format/webp)

```
C已知，那么 a , b 条件独立
```

##### V型结构

![img](https://upload-images.jianshu.io/upload_images/2349903-c39639a1dec2419f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/206/format/webp)

```
也称作 '冲撞结构'
给定C , 那么 a b 必定不独立
若C 未知，那么a,b是相互独立的
```

$$
P(a,b)=\sum_{c}P(a,b,c)\\
=\sum_{c}P(c|a,b)P(a)P(b)\\
=P(a)P(b)
$$

如上性质称作 **边际独立性**

#### 学习过程

##### 评分搜索

```
定义一个 评分函数，以此来评估贝叶斯网和训练数据之间的契合程度
```

